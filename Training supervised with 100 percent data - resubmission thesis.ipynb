{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36007f32",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/captaingaga/water-quality-70-acc-optuna-svm-iterativeimputer/notebook\n",
    "https://www.kaggle.com/code/muhammetgamal5/kfold-cross-validation-optuna-tuning/notebook\n",
    "https://www.kaggle.com/code/neilgibbons/tuning-tabnet-with-optuna\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482fa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7aedd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import sklearn.svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955e2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\Mumtaz\\Desktop\\Thesis data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd0280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c62efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target variable\n",
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5490fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to right types\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].map({1: 'Yes', 0: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with median\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c21c52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column customerID, this is not relevant\n",
    "df.drop(columns=['customerID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e04f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to binary\n",
    "df['gender'].replace({'Female':1,'Male':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e2225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify value\n",
    "df.replace('No internet service', 'No', inplace=True)\n",
    "df.replace('No phone service', 'No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790c1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for features with multiple categories\n",
    "multiple_categories = ['InternetService' ,'Contract' ,'PaymentMethod']\n",
    "df = pd.get_dummies(data=df, columns= multiple_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df089cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode binary values\n",
    "categories = df[['SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup','DeviceProtection','TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']]\n",
    "for i in categories:\n",
    "    df[i].replace({\"No\":0, \"Yes\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0156b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21da1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3445bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train[['tenure', 'MonthlyCharges', 'TotalCharges']] = StandardScaler().fit_transform(X_train[['tenure', 'MonthlyCharges', 'TotalCharges']])\n",
    "X_test[['tenure', 'MonthlyCharges', 'TotalCharges']] = StandardScaler().fit_transform(X_test[['tenure', 'MonthlyCharges', 'TotalCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1910393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has 4139 samples\n",
      "Class 1 has 1495 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mumtaz\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has 4139 samples after oversampling\n",
      "Class 1 has 4162 samples after oversampling\n"
     ]
    }
   ],
   "source": [
    "# Smote for training set\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "for label, count in zip(*np.unique(y_train, return_counts=True)):\n",
    "    print('Class {} has {} samples'.format(label, count))\n",
    "\n",
    "kmeans_smote = KMeansSMOTE(\n",
    "    sampling_strategy = 'not majority',\n",
    "    random_state = 42,\n",
    "    k_neighbors = 10,\n",
    "    cluster_balance_threshold = 0.1,\n",
    "    kmeans_estimator = MiniBatchKMeans(n_clusters=100, random_state=42)\n",
    ")\n",
    "X_train, y_train = kmeans_smote.fit_resample(X_train, y_train)\n",
    "\n",
    "for label, count in zip(*np.unique(y_train, return_counts=True)):\n",
    "    print('Class {} has {} samples after oversampling'.format(label, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ea72514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4162\n",
       "0    4139\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target variable\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ad9fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :(8301, 26), y_train shape: (8301,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape :{X_train.shape}, y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "887e3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.rename(columns={'InternetService_Fiber optic': 'InternetService_Fiber_optic', 'Contract_One year' : 'Contract_One_year', 'Contract_Two year': 'Contract_Two_year',\n",
    "                      'PaymentMethod_Bank transfer (automatic)':'PaymentMethod_Bank_transfer_automatic', 'PaymentMethod_Credit card (automatic)':'PaymentMethod_Creditcard_automatic)',\n",
    "                      'PaymentMethod_Electronic check': 'PaymentMethod_Electronic_check', 'PaymentMethod_Mailed check': 'PaymentMethod_Mailed_check'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adac2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.rename(columns={'InternetService_Fiber optic': 'InternetService_Fiber_optic', 'Contract_One year' : 'Contract_One_year', 'Contract_Two year': 'Contract_Two_year',\n",
    "                      'PaymentMethod_Bank transfer (automatic)':'PaymentMethod_Bank_transfer_automatic', 'PaymentMethod_Credit card (automatic)':'PaymentMethod_Creditcard_automatic)',\n",
    "                      'PaymentMethod_Electronic check': 'PaymentMethod_Electronic_check', 'PaymentMethod_Mailed check': 'PaymentMethod_Mailed_check'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde4a70",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf3a9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_params = ({'n_estimators': 1986, 'max_depth': 13, 'learning_rate': 0.044627773598530054, 'gamma': 0.280206721005955, 'subsample': 0.58545974420027, 'min_child_weight': 2.3451283944922916, 'reg_lambda': 1.9688536003000663, 'reg_alpha': 1.6563747476472204, 'colsample_bytree': 0.7486193155195076})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be8e36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85920578 0.82771084 0.85542169 0.84216867 0.86385542 0.84819277\n",
      " 0.87710843 0.86024096 0.84337349 0.82650602]\n",
      "0.85 accuracy with a standard deviation of 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.9min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "XGBOOST_model = XGBClassifier(**XGBoost_params)\n",
    "kfold_val = KFold(10, shuffle=True, random_state=42)\n",
    "cv_score = cross_val_score(XGBOOST_model, X_train, y_train, cv=kfold_val, verbose=1)\n",
    "print(cv_score)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39d5df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for training: 32.54776720000001 seconds\n",
      "Time consumed for prediction: 0.11529039999999213 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "final_xgb_model = XGBClassifier(**XGBoost_params)\n",
    "xgb_train_start = time.perf_counter()\n",
    "final_xgb_model.fit(X_train, y_train)\n",
    "xgb_train_end = time.perf_counter()\n",
    "\n",
    "xgb_pred_start = time.perf_counter()\n",
    "final_xgb_preds = final_xgb_model.predict(X_test)\n",
    "xgb_pred_end = time.perf_counter()\n",
    "\n",
    "xgb_train_time = xgb_train_end-xgb_train_start\n",
    "xgb_pred_time = xgb_pred_end-xgb_pred_start\n",
    "\n",
    "print(\"Time consumed for training:\" ,xgb_train_time, \"seconds\")\n",
    "print(\"Time consumed for prediction:\" ,xgb_pred_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8dd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82      1035\n",
      "           1       0.52      0.74      0.61       374\n",
      "\n",
      "    accuracy                           0.75      1409\n",
      "   macro avg       0.71      0.75      0.72      1409\n",
      "weighted avg       0.79      0.75      0.76      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, final_xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9944f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for training: 33.11593190000002 seconds\n",
      "Time consumed for prediction: 0.11392019999999548 seconds\n"
     ]
    }
   ],
   "source": [
    "final_xgb_model = XGBClassifier(**XGBoost_params)\n",
    "xgb_train_start = time.perf_counter()\n",
    "final_xgb_model.fit(X_train, y_train)\n",
    "xgb_train_end = time.perf_counter()\n",
    "\n",
    "xgb_pred_start = time.perf_counter()\n",
    "final_xgb_preds_proba = final_xgb_model.predict_proba(X_test)[:,1]\n",
    "xgb_pred_end = time.perf_counter()\n",
    "\n",
    "xgb_train_time = xgb_train_end-xgb_train_start\n",
    "xgb_pred_time = xgb_pred_end-xgb_pred_start\n",
    "\n",
    "print(\"Time consumed for training:\" ,xgb_train_time, \"seconds\")\n",
    "print(\"Time consumed for prediction:\" ,xgb_pred_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39e2ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC score is 0.8232555736392054\n"
     ]
    }
   ],
   "source": [
    "xgb_score=roc_auc_score(y_test, final_xgb_preds_proba)\n",
    "print(\"The ROC AUC score is\" ,xgb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fc040",
   "metadata": {},
   "source": [
    "# SVM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48678692",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_params = ({'C': 1, 'gamma': 1, 'kernel': 'rbf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0d0a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86762936 0.83253012 0.85301205 0.8373494  0.8626506  0.84698795\n",
      " 0.88192771 0.86626506 0.84457831 0.82891566]\n",
      "0.85 accuracy with a standard deviation of 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   57.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "SVM_model = SVC(**SVC_params)\n",
    "kfold_val = KFold(10, shuffle=True, random_state=42)\n",
    "cv_score = cross_val_score(SVM_model, X_train, y_train, cv=kfold_val, verbose=1)\n",
    "print(cv_score)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45b90302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for training: 5.983721900000035 seconds\n",
      "Time consumed for prediction: 1.376708399999984 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "final_svm_model = SVC(**SVC_params)\n",
    "svm_train_start = time.perf_counter()\n",
    "final_svm_model.fit(X_train, y_train)\n",
    "svm_train_end = time.perf_counter()\n",
    "\n",
    "svm_pred_start = time.perf_counter()\n",
    "final_svm_preds = final_svm_model.predict(X_test)\n",
    "svm_pred_end = time.perf_counter()\n",
    "\n",
    "svm_train_time = svm_train_end-svm_train_start\n",
    "svm_pred_time = svm_pred_end-svm_pred_start\n",
    "\n",
    "print(\"Time consumed for training:\" ,svm_train_time, \"seconds\")\n",
    "print(\"Time consumed for prediction:\" ,svm_pred_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95e03a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      1035\n",
      "           1       0.57      0.58      0.58       374\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.71      0.71      0.71      1409\n",
      "weighted avg       0.77      0.77      0.77      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, final_svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7f332c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for training: 36.5313256 seconds\n",
      "Time consumed for prediction: 1.4222895000000335 seconds\n"
     ]
    }
   ],
   "source": [
    "final_svm_model = SVC(**SVC_params, probability=True)\n",
    "svm_train_start = time.perf_counter()\n",
    "final_svm_model.fit(X_train, y_train)\n",
    "svm_train_end = time.perf_counter()\n",
    "\n",
    "svm_pred_start = time.perf_counter()\n",
    "final_svm_preds_proba = final_svm_model.predict_proba(X_test)[:,1]\n",
    "svm_pred_end = time.perf_counter()\n",
    "\n",
    "svm_train_time = svm_train_end-svm_train_start\n",
    "svm_pred_time = svm_pred_end-svm_pred_start\n",
    "\n",
    "print(\"Time consumed for training:\" ,svm_train_time, \"seconds\")\n",
    "print(\"Time consumed for prediction:\" ,svm_pred_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab114e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC score is 0.783189955824227\n"
     ]
    }
   ],
   "source": [
    "svm_score=roc_auc_score(y_test, final_svm_preds_proba)\n",
    "print(\"The ROC AUC score is\" ,svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2492507",
   "metadata": {},
   "source": [
    "# TabNet pre-trainer & classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "752d8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data to numpy arrays for Pytorch (since it only deals with tensors)\n",
    "X_train_np = X_train.to_numpy()\n",
    "y_train_np = y_train.to_numpy().squeeze()\n",
    "X_test_np  = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8789684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TabNet_params = ({'mask_type': 'entmax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.4, 'n_shared': 1, 'lambda_sparse': 0.00031950274925103057, 'patienceScheduler': 5, 'patience': 18, 'epochs': 91})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b901ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_TabNet_params = dict(n_d=TabNet_params['n_da'], n_a=TabNet_params['n_da'], n_steps=TabNet_params['n_steps'], gamma=TabNet_params['gamma'],\n",
    "                     lambda_sparse=TabNet_params['lambda_sparse'], optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=TabNet_params['mask_type'], n_shared=TabNet_params['n_shared'],\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=TabNet_params['patienceScheduler'],\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=0,\n",
    "                     )\n",
    "epochs = TabNet_params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38e2b52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84115523 0.80722892 0.83493976 0.82650602 0.8626506  0.82650602\n",
      " 0.83253012 0.8313253  0.82048193 0.80722892]\n",
      "0.83 accuracy with a standard deviation of 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 117.2min finished\n"
     ]
    }
   ],
   "source": [
    "TabNetclf_model = TabNetClassifier(**final_TabNet_params)\n",
    "kfold_val = KFold(10, shuffle=True, random_state=42)\n",
    "cv_score = cross_val_score(TabNetclf_model, X_train_np, y_train_np, cv=kfold_val, verbose=1, scoring='accuracy')\n",
    "print(cv_score)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d791f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for training: 716.9731405999992 seconds\n",
      "Time consumed for prediction: 0.5530815999991319 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "TabNet_clf = TabNetClassifier(**final_TabNet_params)\n",
    "clf_train_start = time.perf_counter()\n",
    "TabNet_clf.fit(X_train_np, y_train_np, patience=TabNet_params['patience'], max_epochs=epochs)\n",
    "clf_train_end = time.perf_counter()\n",
    "\n",
    "clf_pred_start = time.perf_counter()\n",
    "clf_preds = TabNet_clf.predict(X_test_np)\n",
    "clf_pred_end = time.perf_counter()\n",
    "\n",
    "clf_train_time = clf_train_end-clf_train_start\n",
    "clf_pred_time = clf_pred_end-clf_pred_start\n",
    "\n",
    "print(\"Time consumed for training:\" ,clf_train_time, \"seconds\")\n",
    "print(\"Time consumed for prediction:\" ,clf_pred_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d2183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1035\n",
      "           1       0.50      0.55      0.52       374\n",
      "\n",
      "    accuracy                           0.73      1409\n",
      "   macro avg       0.67      0.67      0.67      1409\n",
      "weighted avg       0.74      0.73      0.74      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_np, clf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9788c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for training: 699.1366355999999 seconds\n",
      "Time consumed for prediction: 0.712472400000479 seconds\n"
     ]
    }
   ],
   "source": [
    "TabNet_clf = TabNetClassifier(**final_TabNet_params)\n",
    "clf_train_start = time.perf_counter()\n",
    "TabNet_clf.fit(X_train_np, y_train_np, patience=TabNet_params['patience'], max_epochs=epochs)\n",
    "clf_train_end = time.perf_counter()\n",
    "\n",
    "clf_pred_start = time.perf_counter()\n",
    "clf_preds_proba = TabNet_clf.predict_proba(X_test_np)[:,1]\n",
    "clf_pred_end = time.perf_counter()\n",
    "\n",
    "clf_train_time = clf_train_end-clf_train_start\n",
    "clf_pred_time = clf_pred_end-clf_pred_start\n",
    "\n",
    "print(\"Time consumed for training:\" ,clf_train_time, \"seconds\")\n",
    "print(\"Time consumed for prediction:\" ,clf_pred_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4df9a88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC score is 0.763734532020977\n"
     ]
    }
   ],
   "source": [
    "clf_score=roc_auc_score(y_test, clf_preds_proba)\n",
    "print(\"The ROC AUC score is\" ,clf_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
